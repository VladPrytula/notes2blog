{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3be122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing simulation environment and agents...\n",
      "Running simulation for LinUCBAgent...\n",
      "Running simulation for LinUCBAgent...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce43024a8a32412c901f24233a37cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation complete. Average reward: 0.4798\n",
      "Running simulation for NeuralUCBAgent...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19e4ea1a6eb44a7b10c8a9b9346a240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m simulator = ZooplusSimulator(n_products=N_PRODUCTS, seed=SEED)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Run the simulation for the NeuralUCB agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mNeuralUCB (Shared)\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneural_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_interactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_INTERACTIONS\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# --- 5. Analysis & Visualization ---\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlotting results...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src_local/notes_to_post/shared_code/common_utils.py:159\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(agent, simulator, num_interactions)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# **THE FIX: Pass the dynamic list of personas from the simulator**\u001b[39;00m\n\u001b[32m    157\u001b[39m all_feature_vectors = create_feature_vectors(user_persona, simulator.products, simulator.persona_names)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m chosen_arm_idx = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_feature_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m reward = simulator.get_reward(user_id, product_id=chosen_arm_idx)\n\u001b[32m    162\u001b[39m chosen_feature_vector = all_feature_vectors[chosen_arm_idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src_local/notes_to_post/shared_code/chapter3_utils.py:85\u001b[39m, in \u001b[36mNeuralUCBAgent.predict\u001b[39m\u001b[34m(self, feature_vectors)\u001b[39m\n\u001b[32m     82\u001b[39m     grads = torch.autograd.grad(pred, params.values())\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([g.view(-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m J = \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_grad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.last_jacobian = J\n\u001b[32m     88\u001b[39m bonus_squared = torch.einsum(\u001b[33m'\u001b[39m\u001b[33mij,ji->i\u001b[39m\u001b[33m'\u001b[39m, J @ A_inv, J.T)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/blog/lib/python3.12/site-packages/torch/_functorch/apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/blog/lib/python3.12/site-packages/torch/_functorch/vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/blog/lib/python3.12/site-packages/torch/_functorch/vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src_local/notes_to_post/shared_code/chapter3_utils.py:82\u001b[39m, in \u001b[36mNeuralUCBAgent.predict.<locals>.compute_grad\u001b[39m\u001b[34m(x_single)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_grad\u001b[39m(x_single):\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# functional_call will now use parameters that require gradients\u001b[39;00m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# within a clean autograd context.\u001b[39;00m\n\u001b[32m     81\u001b[39m     pred = functional_call(\u001b[38;5;28mself\u001b[39m.model, (params, buffers), args=(x_single.unsqueeze(\u001b[32m0\u001b[39m),))\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     grads = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([g.view(-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/blog/lib/python3.12/site-packages/torch/autograd/__init__.py:502\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    498\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    499\u001b[39m         grad_outputs_\n\u001b[32m    500\u001b[39m     )\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    513\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    514\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    515\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/blog/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Experiment notebook: Chapter 3 extracted code dry run\n",
    "from shared_code.common_utils import ZooplusSimulator, run_simulation, plot_results\n",
    "from shared_code.chapter3_utils import NeuralUCBAgent, FEATURE_DIM\n",
    "from shared_code.chapter2_utils import LinUCBAgent  # Assuming LinUCBAgent is defined here\n",
    "\n",
    "# --- Experiment Setup ---\n",
    "NUM_INTERACTIONS = 20_000\n",
    "N_PRODUCTS = 50\n",
    "ALPHA = 1.5\n",
    "\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "NUM_INTERACTIONS = 25_000\n",
    "N_PRODUCTS = 50\n",
    "ALPHA = 1.5          # Exploration-exploitation trade-off parameter\n",
    "LAMBDA = 1.0         # Regularization parameter for LinUCB\n",
    "LEARNING_RATE = 0.01 # Learning rate for the NeuralUCB optimizer\n",
    "SEED = 42            # For reproducibility\n",
    "\n",
    "# --- 3. Initialization ---\n",
    "print(\"Initializing simulation environment and agents...\")\n",
    "\n",
    "# Initialize the environment\n",
    "simulator = ZooplusSimulator(n_products=N_PRODUCTS, seed=SEED)\n",
    "\n",
    "# **THE FIX: Get feature dimension directly from the initialized simulator**\n",
    "FEATURE_DIM = simulator.feature_dim \n",
    "\n",
    "# Initialize the Disjoint LinUCB Agent from Chapter 2\n",
    "linucb_agent = LinUCBAgent(\n",
    "    n_arms=N_PRODUCTS,\n",
    "    feature_dim=FEATURE_DIM,\n",
    "    lambda_=LAMBDA,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "\n",
    "# Initialize the NeuralUCB Agent from Chapter 3\n",
    "neural_agent = NeuralUCBAgent(\n",
    "    feature_dim=FEATURE_DIM,\n",
    "    hidden_dims=[100, 100],  # A reasonably expressive network\n",
    "    lambda_=LAMBDA,          # Note: this lambda is for the UCB matrix, not the network optimizer\n",
    "    alpha=ALPHA,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# --- 4. Execution ---\n",
    "# We store the results in a dictionary for easy plotting\n",
    "results = {}\n",
    "\n",
    "# Run the simulation for the LinUCB agent\n",
    "results[\"LinUCB (Disjoint)\"] = run_simulation(\n",
    "    agent=linucb_agent,\n",
    "    simulator=simulator,\n",
    "    num_interactions=NUM_INTERACTIONS\n",
    ")\n",
    "\n",
    "# Re-initialize the simulator with the same seed to ensure the sequence of\n",
    "# users is identical for a fair comparison.\n",
    "simulator = ZooplusSimulator(n_products=N_PRODUCTS, seed=SEED)\n",
    "\n",
    "# Run the simulation for the NeuralUCB agent\n",
    "results[\"NeuralUCB (Shared)\"] = run_simulation(\n",
    "    agent=neural_agent,\n",
    "    simulator=simulator,\n",
    "    num_interactions=NUM_INTERACTIONS\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Analysis & Visualization ---\n",
    "print(\"\\nPlotting results...\")\n",
    "plot_results(results, window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36875566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
