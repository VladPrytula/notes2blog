{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7383bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is mac mps specific\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e45b24",
   "metadata": {},
   "source": [
    "## **Part II: Understanding the User's Journey and Network**\n",
    "\n",
    "### **Chapter 3: The Session-Aware Recommender: Sequential Models for In-the-Moment Personalization**\n",
    "\n",
    "#### **3.1 Introduction: Beyond a Single Click - Modeling User Intent**\n",
    "\n",
    "In the previous chapters, we built and contrasted two powerful but fundamentally different recommendation paradigms. Our batched MLP model learned a static, long-term profile of a user's preferences. Our LinUCB agent learned to adapt to these preferences in real-time, intelligently exploring to maximize rewards over time. Yet, both models share a critical blind spot: they are largely \"memoryless\" on a moment-to-moment basis. They treat each user interaction as an isolated event, failing to consider the rich context provided by the user's *immediate* actions within the current browsing session.\n",
    "\n",
    "Consider Anna, our `new_puppy_parent`. Her long-term profile indicates a preference for dog-related products. But what is she trying to accomplish *right now*?\n",
    "*   **Session A:** She clicks on \"Puppy Food,\" then \"Food Bowl,\" then \"Water Dispenser.\" Her intent is clear: she is setting up the feeding station for her new pet. The next logical recommendation is not a random dog toy, but perhaps \"Puppy Training Treats\" or a \"Placemat for Food Bowls.\"\n",
    "*   **Session B:** A few weeks later, she clicks on \"Flea & Tick Prevention,\" then \"Dog Shampoo,\" then \"Grooming Brush.\" Her current mission is pet hygiene. The best recommendation would be \"Nail Clippers\" or \"Medicated Ear Wipes.\"\n",
    "\n",
    "Both the static MLP and the contextual bandit would struggle to distinguish between these two sessions. They see a `new_puppy_parent` and recommend a high-average-CTR item like a \"Dog Toy,\" missing the specific, in-the-moment user intent.\n",
    "\n",
    "This is the limitation we will address in this chapter. We will move beyond single-interaction predictions and build a **session-aware recommender**. Our goal is to model the *sequence* of a user's actions to predict their next move. By understanding the \"grammar\" of a user's journey, we can achieve a much deeper and more responsive form of personalization.\n",
    "\n",
    "#### **3.2 The Frontier Technique: Transformer Architectures for Recommendations**\n",
    "\n",
    "To model sequences, the natural inclination for many years was to turn to Recurrent Neural Networks (RNNs) and their more powerful variants like LSTMs and GRUs. These models process a sequence element by element, maintaining a \"hidden state\" that acts as a memory of what has been seen so far. While effective, they suffer from two key weaknesses: difficulty in capturing very long-range dependencies and an inherently sequential nature that makes them difficult to parallelize during training.\n",
    "\n",
    "The modern solution, which has revolutionized natural language processing and is now a frontier technique in recommendations, is the **Transformer architecture**. The power of the Transformer lies in its core mechanism: **self-attention**.\n",
    "\n",
    "Instead of processing a sequence one item at a time, the self-attention mechanism allows the model to look at the entire sequence at once and, for each item, calculate an \"attention score\" that determines how important all other items in the sequence are to it. In our Zooplus example, when predicting the item that should follow \"Puppy Food\" -> \"Food Bowl\", the self-attention mechanism can learn that \"Puppy Food\" is a much more important clue than an unrelated item clicked at the beginning of the session.\n",
    "\n",
    "We will implement a specific, well-regarded Transformer-based model for recommendations: the **Behavioral Sequence Transformer (BST)**. The architecture is an elegant application of the Transformer's encoder block for the task of next-item prediction.\n",
    "\n",
    "Here's a conceptual overview of the BST model:\n",
    "1.  **Inputs:** The model takes two primary inputs: a user's recent behavior sequence (e.g., the last 10 products they clicked on) and a \"target item\" (a candidate product we are considering recommending).\n",
    "2.  **Embedding:** All items in the behavior sequence and the target item are converted from IDs into dense, learned embedding vectors. This is the same `nn.Embedding` concept from Chapter 1.\n",
    "3.  **Positional Encoding:** Because the self-attention mechanism itself has no inherent sense of order, we add a \"positional embedding\" to each item in the sequence. This vector encodes the item's position (e.g., 1st, 2nd, 3rd...), giving the model a crucial sense of temporality.\n",
    "4.  **Transformer Encoder (Self-Attention):** The sequence of (item + positional) embeddings is fed into a Transformer Encoder layer. This layer performs self-attention, allowing every item to \"communicate\" with every other item. The output is a new sequence of context-aware embeddings, where each item's representation has been enriched with information from its neighbors.\n",
    "5.  **Aggregation & Prediction:** The context-aware embeddings from the sequence are aggregated (e.g., averaged or concatenated). This aggregated vector, representing the user's overall session intent, is then combined with the target item's embedding.\n",
    "6.  **MLP Tower:** This final combined vector is passed through a few dense layers (an MLP) to produce a final prediction: the probability that the user will click on the target item, given their behavior sequence.\n",
    "\n",
    "Let's begin by preparing our data for this new, sequence-aware model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb082b2a",
   "metadata": {},
   "source": [
    "### **3.3 Building a Behavioral Sequence Transformer (BST) for Zooplus**\n",
    "\n",
    "#### **Step 1: Preparing Sequential Data - A Detailed Walkthrough**\n",
    "\n",
    "Before we can build our Transformer model, we must first reshape our data. Our current `interaction_log` is a simple list of events: `(user_id, product_id, clicked)`. A sequential model, however, doesn't learn from isolated events. It learns from *ordered sequences*. Our goal in this section is to convert our flat log into a structured dataset where each sample looks like this:\n",
    "\n",
    "`(a user's recent history, a candidate item, a label telling us if the user clicked it)`\n",
    "\n",
    "This process involves several critical data manipulation and feature engineering steps. Let's break down the code you provided, piece by piece, to understand the logic.\n",
    "\n",
    "```python\n",
    "# Adjust simulator to use 1-based indexing for products.\n",
    "sim = ZooplusSimulator(n_products=50, seed=42)\n",
    "sim.products.index = sim.products.index + 1 # Shift index to be 1 to 50\n",
    "\n",
    "# We only need the interactions of users who actually clicked on something\n",
    "interaction_log = generate_training_data(sim, 200_000)\n",
    "interaction_log = interaction_log[interaction_log['clicked'] == 1].drop('clicked', axis=1)\n",
    "\n",
    "# ... (create_sequences and generate_negative_samples functions) ...\n",
    "```\n",
    "\n",
    "#### **Dissection 1: The Importance of Padding and 1-Based Indexing**\n",
    "\n",
    "```python\n",
    "# Adjust simulator to use 1-based indexing for products.\n",
    "sim = ZooplusSimulator(n_products=50, seed=42)\n",
    "sim.products.index = sim.products.index + 1 # Shift index to be 1 to 50\n",
    "```\n",
    "\n",
    "**Why do we do this?**\n",
    "\n",
    "Our Transformer model will require that every input sequence has the exact same length (e.g., `MAX_SEQ_LEN = 10`). However, real user sessions are variable. A user might click on 2 items, while another clicks on 15. To handle this, we use a technique called **padding**.\n",
    "\n",
    "If a user's history is `[product_45, product_12]`, and our model expects a sequence of length 10, we will \"pad\" the history to the left with a special token:\n",
    "\n",
    "`[<PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, product_45, product_12]`\n",
    "\n",
    "The model needs to know that `<PAD>` is not a real product and should be ignored. The easiest way to create this special token is to reserve the integer `0` for it. By shifting all our real product IDs to start from `1` (`1` to `50`), we free up `0` to be our unique, unambiguous padding value. This is a standard and essential practice when working with sequences in deep learning.\n",
    "\n",
    "#### **Dissection 2: Focusing on Positive Interactions**\n",
    "\n",
    "```python\n",
    "# We only need the interactions of users who actually clicked on something\n",
    "interaction_log = generate_training_data(sim, 200_000)\n",
    "interaction_log = interaction_log[interaction_log['clicked'] == 1].drop('clicked', axis=1)\n",
    "```\n",
    "**Why do we filter for `clicked == 1`?**\n",
    "\n",
    "Our goal is to model a user's *intent*. A user's intent is most clearly expressed by the items they actively choose to engage with (i.e., click on). The sequence of items they *ignored* is much less informative and far noisier. By building our historical sequences only from clicked items, we are training the model on the strongest signal of user interest. We are asking it to learn the \"grammar\" of a successful user journey.\n",
    "\n",
    "#### **Dissection 3: The `create_sequences` Function (The Sliding Window)**\n",
    "\n",
    "This function is the heart of the data transformation. It takes the log of clicks and creates the `(history, target)` pairs.\n",
    "\n",
    "```python\n",
    "def create_sequences(df, max_len=10):\n",
    "    sequences = []\n",
    "    # Step A: Group by user\n",
    "    user_groups = df.groupby('user_id')['product_id'].apply(list)\n",
    "\n",
    "    for user_id, user_interactions in tqdm(user_groups.items(), desc=\"Creating Sequences\"):\n",
    "        # Step B: Ensure sequence is long enough\n",
    "        if len(user_interactions) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Step C: The sliding window\n",
    "        for i in range(1, len(user_interactions)):\n",
    "            history = user_interactions[max(0, i - max_len):i]\n",
    "            target = user_interactions[i]\n",
    "            \n",
    "            # Step D: Padding\n",
    "            padded_history = np.pad(history, (max_len - len(history), 0), 'constant', constant_values=0)\n",
    "            sequences.append((padded_history, target))\n",
    "    return pd.DataFrame(sequences, columns=['history', 'target_item_id'])\n",
    "```\n",
    "\n",
    "*   **Step A: `groupby('user_id')`**: Before we can create a sequence, we must first gather all the actions performed by a single user and put them in order. This gives us an individual timeline for each user.\n",
    "*   **Step B: `if len < 2`**: A sequence requires at least two items: one for the history and one for the target. A user who only ever clicked one item in total provides no sequential information for us to learn from, so we skip them.\n",
    "*   **Step C: The Sliding Window `for i in range(...)`**: This is the core logic. Let's visualize it. Imagine a user clicked on items `[p1, p2, p3, p4]`. This loop generates the following training examples:\n",
    "    1.  `i = 1`: `history = [p1]`, `target = p2`\n",
    "    2.  `i = 2`: `history = [p1, p2]`, `target = p3`\n",
    "    3.  `i = 3`: `history = [p1, p2, p3]`, `target = p4`\n",
    "    This brilliantly multiplies our data, allowing the model to learn from every step of the user's journey. The `max(0, i - max_len)` part ensures we don't try to go back further than the start of the sequence while respecting our maximum length.\n",
    "*   **Step D: `np.pad`**: Here we apply the padding concept discussed earlier. The arguments `(max_len - len(history), 0)` tell NumPy to add padding *only to the left* of our history array, and `constant_values=0` specifies that our `<PAD>` token is the integer `0`.\n",
    "\n",
    "#### **Dissection 4: The `generate_negative_samples` Function (The Most Important Step)**\n",
    "\n",
    "After `create_sequences`, our `seq_data` DataFrame contains thousands of `(history, target)` pairs. These are all **positive examples**—the `target` is always an item the user actually clicked.\n",
    "\n",
    "**Why is this a problem?** If we only train the model on positive examples, it will learn a useless strategy: \"No matter the history or target item, always predict a click probability of 1.0.\" It has never seen an example of a \"bad\" recommendation, so it has no incentive to learn to distinguish good from bad.\n",
    "\n",
    "To solve this, we must create **negative samples**.\n",
    "\n",
    "```python\n",
    "def generate_negative_samples(df, n_products):\n",
    "    # Step A: Copy the positive examples' histories\n",
    "    neg_df = df.copy()\n",
    "    \n",
    "    # Step B: Create random targets\n",
    "    random_negatives = np.random.randint(1, n_products + 1, size=len(df))\n",
    "    neg_df['target_item_id'] = random_negatives\n",
    "    \n",
    "    # Step C: Assign labels\n",
    "    df['label'] = 1\n",
    "    neg_df['label'] = 0\n",
    "    \n",
    "    # Step D: Combine and shuffle\n",
    "    return pd.concat([df, neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "```\n",
    "\n",
    "*   **Step A & B**: For each *real* sequence `(history -> good_target)`, we create a corresponding *fake* sequence `(history -> bad_target)`. We do this by keeping the `history` the same but replacing the `good_target` with a `bad_target` chosen randomly from the entire product catalog. The assumption is that a random item is highly unlikely to be the specific item the user wanted next.\n",
    "*   **Step C**: We label the real examples with `1` (positive) and the fake examples with `0` (negative). Now the model has a clear task: learn to output a high score for the positive pairs and a low score for the negative pairs.\n",
    "*   **Step D**: We combine the positive and negative sets and shuffle them thoroughly. Shuffling is critical to ensure that when we train in mini-batches, each batch contains a mix of positive and negative examples, preventing the model from getting biased during training.\n",
    "\n",
    "> **A Deeper Dive: Is Random Negative Sampling Perfect?**\n",
    ">\n",
    "> No, it's a simple and effective starting point. A known issue is the \"false negative\" problem: what if we randomly sample a product that the user *would have* clicked? We are incorrectly teaching the model that this was a bad recommendation. More advanced techniques exist, such as \"in-batch negative sampling\" or sampling based on item popularity (unpopular items are safer bets for being true negatives), but random sampling provides a very strong baseline.\n",
    "\n",
    "After this final step, we have a clean, structured, and balanced dataset ready to be fed into our Behavioral Sequence Transformer. Each row contains a fixed-length, padded history, a target item, and a label, giving our model everything it needs to learn the subtle art of in-session personalization.\n",
    "\n",
    "Let's now proceed with building and training the model on this well-prepared data.Of course. This is an excellent point and is crucial for making the material truly educational. Providing the \"why\" behind the code is just as important as the code itself.\n",
    "\n",
    "Let's go back and replace the initial data preparation section with a much more detailed, explanatory version that walks through the reasoning for each step.\n",
    "\n",
    "***\n",
    "\n",
    "### **3.3 Building a Behavioral Sequence Transformer (BST) for Zooplus**\n",
    "\n",
    "#### **Step 1: Preparing Sequential Data - A Detailed Walkthrough**\n",
    "\n",
    "Before we can build our Transformer model, we must first reshape our data. Our current `interaction_log` is a simple list of events: `(user_id, product_id, clicked)`. A sequential model, however, doesn't learn from isolated events. It learns from *ordered sequences*. Our goal in this section is to convert our flat log into a structured dataset where each sample looks like this:\n",
    "\n",
    "`(a user's recent history, a candidate item, a label telling us if the user clicked it)`\n",
    "\n",
    "This process involves several critical data manipulation and feature engineering steps. Let's break down the code you provided, piece by piece, to understand the logic.\n",
    "\n",
    "```python\n",
    "# The code block from the prompt is reproduced here for context.\n",
    "# ... (imports and Simulator class definition) ...\n",
    "\n",
    "# Adjust simulator to use 1-based indexing for products.\n",
    "sim = ZooplusSimulator(n_products=50, seed=42)\n",
    "sim.products.index = sim.products.index + 1 # Shift index to be 1 to 50\n",
    "\n",
    "# We only need the interactions of users who actually clicked on something\n",
    "interaction_log = generate_training_data(sim, 200_000)\n",
    "interaction_log = interaction_log[interaction_log['clicked'] == 1].drop('clicked', axis=1)\n",
    "\n",
    "# ... (create_sequences and generate_negative_samples functions) ...\n",
    "```\n",
    "\n",
    "#### **Dissection 1: The Importance of Padding and 1-Based Indexing**\n",
    "\n",
    "```python\n",
    "# Adjust simulator to use 1-based indexing for products.\n",
    "sim = ZooplusSimulator(n_products=50, seed=42)\n",
    "sim.products.index = sim.products.index + 1 # Shift index to be 1 to 50\n",
    "```\n",
    "\n",
    "**Why do we do this?**\n",
    "\n",
    "Our Transformer model will require that every input sequence has the exact same length (e.g., `MAX_SEQ_LEN = 10`). However, real user sessions are variable. A user might click on 2 items, while another clicks on 15. To handle this, we use a technique called **padding**.\n",
    "\n",
    "If a user's history is `[product_45, product_12]`, and our model expects a sequence of length 10, we will \"pad\" the history to the left with a special token:\n",
    "\n",
    "`[<PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, product_45, product_12]`\n",
    "\n",
    "The model needs to know that `<PAD>` is not a real product and should be ignored. The easiest way to create this special token is to reserve the integer `0` for it. By shifting all our real product IDs to start from `1` (`1` to `50`), we free up `0` to be our unique, unambiguous padding value. This is a standard and essential practice when working with sequences in deep learning.\n",
    "\n",
    "#### **Dissection 2: Focusing on Positive Interactions**\n",
    "\n",
    "```python\n",
    "# We only need the interactions of users who actually clicked on something\n",
    "interaction_log = generate_training_data(sim, 200_000)\n",
    "interaction_log = interaction_log[interaction_log['clicked'] == 1].drop('clicked', axis=1)\n",
    "```\n",
    "**Why do we filter for `clicked == 1`?**\n",
    "\n",
    "Our goal is to model a user's *intent*. A user's intent is most clearly expressed by the items they actively choose to engage with (i.e., click on). The sequence of items they *ignored* is much less informative and far noisier. By building our historical sequences only from clicked items, we are training the model on the strongest signal of user interest. We are asking it to learn the \"grammar\" of a successful user journey.\n",
    "\n",
    "#### **Dissection 3: The `create_sequences` Function (The Sliding Window)**\n",
    "\n",
    "This function is the heart of the data transformation. It takes the log of clicks and creates the `(history, target)` pairs.\n",
    "\n",
    "```python\n",
    "def create_sequences(df, max_len=10):\n",
    "    sequences = []\n",
    "    # Step A: Group by user\n",
    "    user_groups = df.groupby('user_id')['product_id'].apply(list)\n",
    "\n",
    "    for user_id, user_interactions in tqdm(user_groups.items(), desc=\"Creating Sequences\"):\n",
    "        # Step B: Ensure sequence is long enough\n",
    "        if len(user_interactions) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Step C: The sliding window\n",
    "        for i in range(1, len(user_interactions)):\n",
    "            history = user_interactions[max(0, i - max_len):i]\n",
    "            target = user_interactions[i]\n",
    "            \n",
    "            # Step D: Padding\n",
    "            padded_history = np.pad(history, (max_len - len(history), 0), 'constant', constant_values=0)\n",
    "            sequences.append((padded_history, target))\n",
    "    return pd.DataFrame(sequences, columns=['history', 'target_item_id'])\n",
    "```\n",
    "\n",
    "*   **Step A: `groupby('user_id')`**: Before we can create a sequence, we must first gather all the actions performed by a single user and put them in order. This gives us an individual timeline for each user.\n",
    "*   **Step B: `if len < 2`**: A sequence requires at least two items: one for the history and one for the target. A user who only ever clicked one item in total provides no sequential information for us to learn from, so we skip them.\n",
    "*   **Step C: The Sliding Window `for i in range(...)`**: This is the core logic. Let's visualize it. Imagine a user clicked on items `[p1, p2, p3, p4]`. This loop generates the following training examples:\n",
    "    1.  `i = 1`: `history = [p1]`, `target = p2`\n",
    "    2.  `i = 2`: `history = [p1, p2]`, `target = p3`\n",
    "    3.  `i = 3`: `history = [p1, p2, p3]`, `target = p4`\n",
    "    This brilliantly multiplies our data, allowing the model to learn from every step of the user's journey. The `max(0, i - max_len)` part ensures we don't try to go back further than the start of the sequence while respecting our maximum length.\n",
    "*   **Step D: `np.pad`**: Here we apply the padding concept discussed earlier. The arguments `(max_len - len(history), 0)` tell NumPy to add padding *only to the left* of our history array, and `constant_values=0` specifies that our `<PAD>` token is the integer `0`.\n",
    "\n",
    "#### **Dissection 4: The `generate_negative_samples` Function (The Most Important Step)**\n",
    "\n",
    "After `create_sequences`, our `seq_data` DataFrame contains thousands of `(history, target)` pairs. These are all **positive examples**—the `target` is always an item the user actually clicked.\n",
    "\n",
    "**Why is this a problem?** If we only train the model on positive examples, it will learn a useless strategy: \"No matter the history or target item, always predict a click probability of 1.0.\" It has never seen an example of a \"bad\" recommendation, so it has no incentive to learn to distinguish good from bad.\n",
    "\n",
    "To solve this, we must create **negative samples**.\n",
    "\n",
    "```python\n",
    "def generate_negative_samples(df, n_products):\n",
    "    # Step A: Copy the positive examples' histories\n",
    "    neg_df = df.copy()\n",
    "    \n",
    "    # Step B: Create random targets\n",
    "    random_negatives = np.random.randint(1, n_products + 1, size=len(df))\n",
    "    neg_df['target_item_id'] = random_negatives\n",
    "    \n",
    "    # Step C: Assign labels\n",
    "    df['label'] = 1\n",
    "    neg_df['label'] = 0\n",
    "    \n",
    "    # Step D: Combine and shuffle\n",
    "    return pd.concat([df, neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "```\n",
    "\n",
    "*   **Step A & B**: For each *real* sequence `(history -> good_target)`, we create a corresponding *fake* sequence `(history -> bad_target)`. We do this by keeping the `history` the same but replacing the `good_target` with a `bad_target` chosen randomly from the entire product catalog. The assumption is that a random item is highly unlikely to be the specific item the user wanted next.\n",
    "*   **Step C**: We label the real examples with `1` (positive) and the fake examples with `0` (negative). Now the model has a clear task: learn to output a high score for the positive pairs and a low score for the negative pairs.\n",
    "*   **Step D**: We combine the positive and negative sets and shuffle them thoroughly. Shuffling is critical to ensure that when we train in mini-batches, each batch contains a mix of positive and negative examples, preventing the model from getting biased during training.\n",
    "\n",
    "> **A Deeper Dive: Is Random Negative Sampling Perfect?**\n",
    ">\n",
    "> No, it's a simple and effective starting point. A known issue is the \"false negative\" problem: what if we randomly sample a product that the user *would have* clicked? We are incorrectly teaching the model that this was a bad recommendation. More advanced techniques exist, such as \"in-batch negative sampling\" or sampling based on item popularity (unpopular items are safer bets for being true negatives), but random sampling provides a very strong baseline.\n",
    "\n",
    "After this final step, we have a clean, structured, and balanced dataset ready to be fed into our Behavioral Sequence Transformer. Each row contains a fixed-length, padded history, a target item, and a label, giving our model everything it needs to learn the subtle art of in-session personalization.\n",
    "\n",
    "Let's now proceed with building and training the model on this well-prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5fe0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Sequences: 1000it [00:00, 4896.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original positive sequences: 41,027\n",
      "Total training samples (positive + negative): 82,054\n",
      "\n",
      "Example of final training data:\n",
      "                                    history  target_item_id  label\n",
      "0    [23, 2, 50, 12, 46, 2, 14, 21, 30, 24]              10      0\n",
      "1  [14, 49, 30, 33, 32, 45, 36, 15, 27, 13]              41      1\n",
      "2   [37, 1, 43, 15, 46, 24, 27, 21, 15, 16]              19      0\n",
      "3   [27, 8, 49, 10, 10, 32, 35, 27, 13, 35]              35      1\n",
      "4   [34, 27, 4, 27, 11, 29, 47, 40, 40, 15]              32      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class ZooplusSimulator:\n",
    "    def __init__(self, n_products=50, n_users=1000, seed=42):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.n_products = n_products\n",
    "        self.n_users = n_users\n",
    "        self.products = self._create_product_catalog()\n",
    "        self.personas = self._create_user_personas()\n",
    "        self.user_to_persona_map = self._assign_users_to_personas()\n",
    "    def _create_product_catalog(self):\n",
    "        product_ids = range(self.n_products)\n",
    "        categories = ['Fish Supplies', 'Cat Food', 'Dog Food', 'Dog Toy', 'Cat Toy']\n",
    "        num_per_category = self.n_products // len(categories)\n",
    "        cat_list = []\n",
    "        for cat in categories: cat_list.extend([cat] * num_per_category)\n",
    "        cat_list.extend(self.rng.choice(categories, self.n_products - len(cat_list)))\n",
    "        return pd.DataFrame({'product_id': product_ids, 'category': self.rng.permutation(cat_list)}).set_index('product_id')\n",
    "    def _create_user_personas(self):\n",
    "        return {\n",
    "            'new_puppy_parent': {'Dog Food': 0.40, 'Dog Toy': 0.50, 'Cat Food': 0.10, 'Cat Toy': 0.05, 'Fish Supplies': 0.02},\n",
    "            'cat_connoisseur':  {'Dog Food': 0.05, 'Dog Toy': 0.02, 'Cat Food': 0.55, 'Cat Toy': 0.45, 'Fish Supplies': 0.05},\n",
    "            'budget_shopper':   {'Dog Food': 0.25, 'Dog Toy': 0.15, 'Cat Food': 0.40, 'Cat Toy': 0.20, 'Fish Supplies': 0.20},\n",
    "            'fish_hobbyist':    {'Dog Food': 0.02, 'Dog Toy': 0.02, 'Cat Food': 0.10, 'Cat Toy': 0.08, 'Fish Supplies': 0.60}\n",
    "        }\n",
    "    def _assign_users_to_personas(self):\n",
    "        persona_names = list(self.personas.keys())\n",
    "        return {user_id: self.rng.choice(persona_names) for user_id in range(self.n_users)}\n",
    "    \n",
    "    def get_reward(self, user_id, product_id):\n",
    "        # Defensive check for robustness\n",
    "        if user_id not in self.user_to_persona_map or product_id not in self.products.index:\n",
    "            return 0\n",
    "            \n",
    "        persona_name = self.user_to_persona_map[user_id]\n",
    "        persona_prefs = self.personas[persona_name]\n",
    "        product_category = self.products.loc[product_id, 'category']\n",
    "        click_prob = persona_prefs.get(product_category, 0.01)\n",
    "        return self.rng.binomial(1, click_prob)\n",
    "    \n",
    "    def get_random_user(self):\n",
    "        return self.rng.integers(0, self.n_users)\n",
    "\n",
    "def generate_training_data(simulator, num_interactions):\n",
    "    user_ids, product_ids, clicks = [], [], []\n",
    "    for _ in range(num_interactions):\n",
    "        user_id = simulator.get_random_user()\n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Generate product_ids from 1 to n_products (inclusive)\n",
    "        product_id = simulator.rng.integers(1, simulator.n_products + 1)\n",
    "        # --- END OF FIX ---\n",
    "        \n",
    "        click = simulator.get_reward(user_id, product_id)\n",
    "        user_ids.append(user_id); product_ids.append(product_id); clicks.append(click)\n",
    "    return pd.DataFrame({'user_id': user_ids, 'product_id': product_ids, 'clicked': clicks})\n",
    "\n",
    "# Adjust simulator to use 1-based indexing for products.\n",
    "sim = ZooplusSimulator(n_products=50, seed=42)\n",
    "sim.products.index = sim.products.index + 1 # Shift index to be 1 to 50\n",
    "\n",
    "# We only need the interactions of users who actually clicked on something\n",
    "interaction_log = generate_training_data(sim, 200_000)\n",
    "interaction_log = interaction_log[interaction_log['clicked'] == 1].drop('clicked', axis=1)\n",
    "\n",
    "def create_sequences(df, max_len=10):\n",
    "    sequences = []\n",
    "    user_groups = df.groupby('user_id')['product_id'].apply(list)\n",
    "    for user_id, user_interactions in tqdm(user_groups.items(), desc=\"Creating Sequences\"):\n",
    "        if len(user_interactions) < 2:\n",
    "            continue\n",
    "        for i in range(1, len(user_interactions)):\n",
    "            history = user_interactions[max(0, i - max_len):i]\n",
    "            target = user_interactions[i]\n",
    "            padded_history = np.pad(history, (max_len - len(history), 0), 'constant', constant_values=0)\n",
    "            sequences.append((padded_history, target))\n",
    "    return pd.DataFrame(sequences, columns=['history', 'target_item_id'])\n",
    "\n",
    "MAX_SEQ_LEN = 10\n",
    "seq_data = create_sequences(interaction_log, max_len=MAX_SEQ_LEN)\n",
    "\n",
    "def generate_negative_samples(df, n_products):\n",
    "    neg_df = df.copy()\n",
    "    random_negatives = np.random.randint(1, n_products + 1, size=len(df))\n",
    "    neg_df['target_item_id'] = random_negatives\n",
    "    df['label'] = 1\n",
    "    neg_df['label'] = 0\n",
    "    return pd.concat([df, neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "final_training_data = generate_negative_samples(seq_data, sim.n_products)\n",
    "\n",
    "print(f\"\\nOriginal positive sequences: {len(seq_data):,}\")\n",
    "print(f\"Total training samples (positive + negative): {len(final_training_data):,}\")\n",
    "print(\"\\nExample of final training data:\")\n",
    "print(final_training_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12715fd8",
   "metadata": {},
   "source": [
    "**Step 2: Implementing the BST Model in PyTorch**\n",
    "\n",
    "With our data prepared, we can now define the model architecture. We will use PyTorch's built-in `nn.TransformerEncoderLayer` as it provides a robust and optimized implementation of the self-attention mechanism.\n",
    "\n",
    "A key detail is the handling of padding. We need to create an \"attention mask\" to tell the Transformer layer which elements in the sequence are real items and which are just padding. The model should not pay attention to padding tokens.\n",
    "\n",
    "**Code Block 3.2: The Behavioral Sequence Transformer (BST) Model**\n",
    "```python\n",
    "# --- Device Configuration ---\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon) device.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device.\")\n",
    "\n",
    "class BSTDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.histories = [torch.tensor(h, dtype=torch.long) for h in df.history.values]\n",
    "        self.targets = torch.tensor(df.target_item_id.values, dtype=torch.long)\n",
    "        self.labels = torch.tensor(df.label.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.histories[idx], self.targets[idx], self.labels[idx]\n",
    "\n",
    "class BehavioralSequenceTransformer(nn.Module):\n",
    "    def __init__(self, n_products, max_len, embed_dim=64, n_heads=4, n_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Note: n_products + 1 to account for the padding token (0)\n",
    "        self.item_embedding = nn.Embedding(n_products + 1, embed_dim, padding_idx=0)\n",
    "        # Learnable positional embedding\n",
    "        self.positional_embedding = nn.Embedding(max_len + 1, embed_dim)\n",
    "        \n",
    "        # Standard Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=n_heads, \n",
    "            dropout=dropout,\n",
    "            batch_first=True # Important: our data is (batch, seq, feature)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Prediction MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, history_seq, target_item):\n",
    "        # Create attention mask for padding\n",
    "        # Shape: (batch_size, seq_len) -> True for padding tokens\n",
    "        attention_mask = (history_seq == 0)\n",
    "\n",
    "        # 1. Embeddings and Positional Encoding\n",
    "        item_embeds = self.item_embedding(history_seq)\n",
    "        \n",
    "        # Create position IDs (1 to max_len)\n",
    "        positions = torch.arange(1, self.max_len + 1, device=history_seq.device).unsqueeze(0)\n",
    "        pos_embeds = self.positional_embedding(positions)\n",
    "        \n",
    "        # Add embeddings together\n",
    "        seq_embeds = item_embeds + pos_embeds\n",
    "\n",
    "        # 2. Transformer Encoder\n",
    "        # The mask will prevent attention to padding tokens\n",
    "        transformer_out = self.transformer_encoder(seq_embeds, src_key_padding_mask=attention_mask)\n",
    "        \n",
    "        # 3. Aggregation\n",
    "        # We'll use a simple average of the transformer outputs, ignoring padding\n",
    "        # We can create a non-padded version of the mask for averaging\n",
    "        mask_for_avg = attention_mask.unsqueeze(-1).expand(transformer_out.size())\n",
    "        transformer_out[mask_for_avg] = 0 # Zero out padding embeddings\n",
    "        # Sum non-padded embeddings and divide by the number of non-padded items\n",
    "        seq_representation = torch.sum(transformer_out, dim=1)\n",
    "        non_pad_counts = (history_seq != 0).sum(dim=1, dtype=torch.float32).unsqueeze(1)\n",
    "        seq_representation = seq_representation / torch.clamp(non_pad_counts, min=1.0) # Avoid division by zero\n",
    "        \n",
    "        # 4. Prediction\n",
    "        target_embed = self.item_embedding(target_item)\n",
    "        combined_rep = torch.cat([seq_representation, target_embed], dim=1)\n",
    "        \n",
    "        output = self.mlp(combined_rep)\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "# --- Instantiate Dataset and Dataloaders ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(final_training_data, test_size=0.2, random_state=42)\n",
    "train_dataset = BSTDataset(train_df)\n",
    "val_dataset = BSTDataset(val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Datasets and DataLoaders are ready.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f015dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon) device.\n",
      "Datasets and DataLoaders are ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Device Configuration ---\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon) device.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device.\")\n",
    "\n",
    "class BSTDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.histories = [torch.tensor(h, dtype=torch.long) for h in df.history.values]\n",
    "        self.targets = torch.tensor(df.target_item_id.values, dtype=torch.long)\n",
    "        self.labels = torch.tensor(df.label.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.histories[idx], self.targets[idx], self.labels[idx]\n",
    "\n",
    "class BehavioralSequenceTransformer(nn.Module):\n",
    "    def __init__(self, n_products, max_len, embed_dim=64, n_heads=4, n_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Note: n_products + 1 to account for the padding token (0)\n",
    "        self.item_embedding = nn.Embedding(n_products + 1, embed_dim, padding_idx=0)\n",
    "        # Learnable positional embedding\n",
    "        self.positional_embedding = nn.Embedding(max_len + 1, embed_dim)\n",
    "        \n",
    "        # Standard Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=n_heads, \n",
    "            dropout=dropout,\n",
    "            batch_first=True # Important: our data is (batch, seq, feature)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Prediction MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, history_seq, target_item):\n",
    "        # Create attention mask for padding\n",
    "        # Shape: (batch_size, seq_len) -> True for padding tokens\n",
    "        attention_mask = (history_seq == 0)\n",
    "\n",
    "        # 1. Embeddings and Positional Encoding\n",
    "        item_embeds = self.item_embedding(history_seq)\n",
    "        \n",
    "        # Create position IDs (1 to max_len)\n",
    "        positions = torch.arange(1, self.max_len + 1, device=history_seq.device).unsqueeze(0)\n",
    "        pos_embeds = self.positional_embedding(positions)\n",
    "        \n",
    "        # Add embeddings together\n",
    "        seq_embeds = item_embeds + pos_embeds\n",
    "\n",
    "        # 2. Transformer Encoder\n",
    "        # The mask will prevent attention to padding tokens\n",
    "        transformer_out = self.transformer_encoder(seq_embeds, src_key_padding_mask=attention_mask)\n",
    "        \n",
    "        # 3. Aggregation\n",
    "        # We'll use a simple average of the transformer outputs, ignoring padding\n",
    "        # We can create a non-padded version of the mask for averaging\n",
    "        mask_for_avg = attention_mask.unsqueeze(-1).expand(transformer_out.size())\n",
    "        transformer_out[mask_for_avg] = 0 # Zero out padding embeddings\n",
    "        # Sum non-padded embeddings and divide by the number of non-padded items\n",
    "        seq_representation = torch.sum(transformer_out, dim=1)\n",
    "        non_pad_counts = (history_seq != 0).sum(dim=1, dtype=torch.float32).unsqueeze(1)\n",
    "        seq_representation = seq_representation / torch.clamp(non_pad_counts, min=1.0) # Avoid division by zero\n",
    "        \n",
    "        # 4. Prediction\n",
    "        target_embed = self.item_embedding(target_item)\n",
    "        combined_rep = torch.cat([seq_representation, target_embed], dim=1)\n",
    "        \n",
    "        output = self.mlp(combined_rep)\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "# --- Instantiate Dataset and Dataloaders ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(final_training_data, test_size=0.2, random_state=42)\n",
    "train_dataset = BSTDataset(train_df)\n",
    "val_dataset = BSTDataset(val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Datasets and DataLoaders are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e54371",
   "metadata": {},
   "source": [
    "#### **3.4 Training and Evaluating the Sequential Model**\n",
    "\n",
    "Now that we have the data pipeline and the model architecture in place, we can write the standard PyTorch training loop to train our BST model. The process is very similar to the one we used for the batched MLP in Chapter 1: we iterate through epochs, and in each epoch, we process mini-batches of data, calculate the loss, and update the model's weights using backpropagation.\n",
    "\n",
    "We will use Binary Cross-Entropy (BCE) as our loss function, which is appropriate for this binary classification task (predicting a click or no-click).\n",
    "\n",
    "**Code Block 3.3: Training the BST Model**\n",
    "```python\n",
    "# --- Instantiate Model, Loss, and Optimizer ---\n",
    "bst_model = BehavioralSequenceTransformer(\n",
    "    n_products=sim.n_products,\n",
    "    max_len=MAX_SEQ_LEN,\n",
    "    embed_dim=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(bst_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\nBST Model Architecture:\")\n",
    "print(bst_model)\n",
    "\n",
    "# --- The Training Loop ---\n",
    "print(\"\\nTraining the BST model...\")\n",
    "n_epochs = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    bst_model.train()\n",
    "    total_train_loss = 0\n",
    "    for history, targets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Train]\"):\n",
    "        history, targets, labels = history.to(device), targets.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = bst_model(history, targets).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    bst_model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for history, targets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Val]\"):\n",
    "            history, targets, labels = history.to(device), targets.to(device), labels.to(device)\n",
    "            outputs = bst_model(history, targets).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f4048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BST Model Architecture:\n",
      "BehavioralSequenceTransformer(\n",
      "  (item_embedding): Embedding(51, 64, padding_idx=0)\n",
      "  (positional_embedding): Embedding(11, 64)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Training the BST model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|██████████| 257/257 [00:06<00:00, 36.84it/s]\n",
      "Epoch 1/5 [Val]:   0%|          | 0/65 [00:00<?, ?it/s]/Users/vladyslavp/miniconda3/envs/blog/lib/python3.12/site-packages/torch/nn/modules/transformer.py:457: UserWarning: The operator 'aten::_nested_tensor_from_mask_left_aligned' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:14.)\n",
      "  ) and not torch._nested_tensor_from_mask_left_aligned(\n",
      "Epoch 1/5 [Val]: 100%|██████████| 65/65 [00:01<00:00, 62.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.6632, Val Loss: 0.6168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|██████████| 257/257 [00:06<00:00, 42.52it/s]\n",
      "Epoch 2/5 [Val]: 100%|██████████| 65/65 [00:00<00:00, 80.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.6135, Val Loss: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|██████████| 257/257 [00:06<00:00, 40.09it/s]\n",
      "Epoch 3/5 [Val]: 100%|██████████| 65/65 [00:00<00:00, 88.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.6074, Val Loss: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train]: 100%|██████████| 257/257 [00:06<00:00, 41.59it/s]\n",
      "Epoch 4/5 [Val]: 100%|██████████| 65/65 [00:00<00:00, 85.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.6053, Val Loss: 0.6056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train]: 100%|██████████| 257/257 [00:06<00:00, 40.33it/s]\n",
      "Epoch 5/5 [Val]: 100%|██████████| 65/65 [00:00<00:00, 81.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.6028, Val Loss: 0.6048\n",
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Instantiate Model, Loss, and Optimizer ---\n",
    "bst_model = BehavioralSequenceTransformer(\n",
    "    n_products=sim.n_products,\n",
    "    max_len=MAX_SEQ_LEN,\n",
    "    embed_dim=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(bst_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\nBST Model Architecture:\")\n",
    "print(bst_model)\n",
    "\n",
    "# --- The Training Loop ---\n",
    "print(\"\\nTraining the BST model...\")\n",
    "n_epochs = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    bst_model.train()\n",
    "    total_train_loss = 0\n",
    "    for history, targets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Train]\"):\n",
    "        history, targets, labels = history.to(device), targets.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = bst_model(history, targets).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    bst_model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for history, targets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Val]\"):\n",
    "            history, targets, labels = history.to(device), targets.to(device), labels.to(device)\n",
    "            outputs = bst_model(history, targets).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea988f8",
   "metadata": {},
   "source": [
    "**Code Block 3.4: Evaluating the BST Model's Understanding of Intent**\n",
    "\n",
    "The ultimate test of our model is whether it has learned to capture session-based intent. A simple loss value doesn't tell us this directly. We need a qualitative evaluation.\n",
    "\n",
    "Let's create two synthetic user sessions that clearly demonstrate different intents and see what our trained model recommends next.\n",
    "\n",
    "1.  **\"Puppy Feeding\" Intent:** A user clicks on `Dog Food` followed by `Dog Toy`. What comes next? A logical recommendation might be another `Dog Toy` or perhaps a related care item.\n",
    "2.  **\"Cat Owner\" Intent:** A user clicks on `Cat Food` followed by `Cat Toy`. The model should strongly prefer other cat-related items.\n",
    "\n",
    "We will feed these histories to the model and ask it to score *all possible products* as the next item. The products with the highest predicted click probability will reveal what the model has learned.\n",
    "\n",
    "```python\n",
    "def get_bst_recommendations(model, history, n_products, device, max_len=10):\n",
    "    \"\"\"\n",
    "    Gets the model's predicted CTR for all products given a history.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Pad the input history\n",
    "    padded_history = np.pad(history, (max_len - len(history), 0), 'constant', constant_values=0)\n",
    "    \n",
    "    # Create tensors\n",
    "    history_tensor = torch.tensor([padded_history] * n_products, dtype=torch.long).to(device)\n",
    "    # Target items are all possible products from 1 to n_products\n",
    "    target_items_tensor = torch.arange(1, n_products + 1, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(history_tensor, target_items_tensor).squeeze().cpu().numpy()\n",
    "        \n",
    "    # Create a DataFrame for easy analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'product_id': np.arange(1, n_products + 1),\n",
    "        'predicted_ctr': scores\n",
    "    })\n",
    "    results_df = results_df.join(sim.products, on='product_id')\n",
    "    return results_df.sort_values('predicted_ctr', ascending=False)\n",
    "\n",
    "# --- Test Case 1: Puppy Feeding Intent ---\n",
    "# Let's find IDs for 'Dog Food' and 'Dog Toy'\n",
    "dog_food_id = sim.products[sim.products['category'] == 'Dog Food'].index[0]\n",
    "dog_toy_id = sim.products[sim.products['category'] == 'Dog Toy'].index[0]\n",
    "puppy_history = [dog_food_id, dog_toy_id]\n",
    "\n",
    "print(\"--- Test Case 1: 'Puppy' Intent ---\")\n",
    "print(f\"Input History: [Dog Food (ID: {dog_food_id}), Dog Toy (ID: {dog_toy_id})]\")\n",
    "puppy_recs = get_bst_recommendations(bst_model, puppy_history, sim.n_products, device, MAX_SEQ_LEN)\n",
    "print(\"Top 5 Recommendations:\")\n",
    "print(puppy_recs.head(5))\n",
    "\n",
    "\n",
    "# --- Test Case 2: Cat Owner Intent ---\n",
    "cat_food_id = sim.products[sim.products['category'] == 'Cat Food'].index[0]\n",
    "cat_toy_id = sim.products[sim.products['category'] == 'Cat Toy'].index[0]\n",
    "cat_history = [cat_food_id, cat_toy_id]\n",
    "\n",
    "print(\"\\n--- Test Case 2: 'Cat' Intent ---\")\n",
    "print(f\"Input History: [Cat Food (ID: {cat_food_id}), Cat Toy (ID: {cat_toy_id})]\")\n",
    "cat_recs = get_bst_recommendations(bst_model, cat_history, sim.n_products, device, MAX_SEQ_LEN)\n",
    "print(\"Top 5 Recommendations:\")\n",
    "print(cat_recs.head(5))\n",
    "\n",
    "\n",
    "# --- Visualizing the difference ---\n",
    "puppy_recs['source'] = 'After Dog Session'\n",
    "cat_recs['source'] = 'After Cat Session'\n",
    "plot_df = pd.concat([puppy_recs, cat_recs])\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=plot_df, x='predicted_ctr', y='category', hue='source',\n",
    "            order=['Dog Toy', 'Dog Food', 'Cat Toy', 'Cat Food', 'Fish Supplies'])\n",
    "plt.title('BST Model Predictions Based on Session History', fontsize=16)\n",
    "plt.xlabel('Predicted CTR')\n",
    "plt.ylabel('Product Category')\n",
    "plt.legend(title='Session Context')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69dee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Case 1: 'Puppy' Intent ---\n",
      "Input History: [Dog Food (ID: 2), Dog Toy (ID: 5)]\n",
      "Top 5 Recommendations:\n",
      "    product_id  predicted_ctr  category\n",
      "20          21       0.666823   Dog Toy\n",
      "11          12       0.662239   Dog Toy\n",
      "22          23       0.661471  Dog Food\n",
      "39          40       0.647389   Dog Toy\n",
      "17          18       0.644584   Dog Toy\n",
      "\n",
      "--- Test Case 2: 'Cat' Intent ---\n",
      "Input History: [Cat Food (ID: 10), Cat Toy (ID: 4)]\n",
      "Top 5 Recommendations:\n",
      "    product_id  predicted_ctr  category\n",
      "48          49       0.692729  Cat Food\n",
      "42          43       0.671624  Cat Food\n",
      "26          27       0.669306  Cat Food\n",
      "38          39       0.668806  Cat Food\n",
      "29          30       0.668392  Cat Food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/4zz7vfq15p72bs6qsv71c45w0000gn/T/ipykernel_67397/3888874839.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  history_tensor = torch.tensor([padded_history] * n_products, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_bst_recommendations(model, history, n_products, device, max_len=10):\n",
    "    \"\"\"\n",
    "    Gets the model's predicted CTR for all products given a history.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Pad the input history\n",
    "    padded_history = np.pad(history, (max_len - len(history), 0), 'constant', constant_values=0)\n",
    "    \n",
    "    # Create tensors\n",
    "    history_tensor = torch.tensor([padded_history] * n_products, dtype=torch.long).to(device)\n",
    "    # Target items are all possible products from 1 to n_products\n",
    "    target_items_tensor = torch.arange(1, n_products + 1, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(history_tensor, target_items_tensor).squeeze().cpu().numpy()\n",
    "        \n",
    "    # Create a DataFrame for easy analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'product_id': np.arange(1, n_products + 1),\n",
    "        'predicted_ctr': scores\n",
    "    })\n",
    "    results_df = results_df.join(sim.products, on='product_id')\n",
    "    return results_df.sort_values('predicted_ctr', ascending=False)\n",
    "\n",
    "# --- Test Case 1: Puppy Feeding Intent ---\n",
    "# Let's find IDs for 'Dog Food' and 'Dog Toy'\n",
    "dog_food_id = sim.products[sim.products['category'] == 'Dog Food'].index[0]\n",
    "dog_toy_id = sim.products[sim.products['category'] == 'Dog Toy'].index[0]\n",
    "puppy_history = [dog_food_id, dog_toy_id]\n",
    "\n",
    "print(\"--- Test Case 1: 'Puppy' Intent ---\")\n",
    "print(f\"Input History: [Dog Food (ID: {dog_food_id}), Dog Toy (ID: {dog_toy_id})]\")\n",
    "puppy_recs = get_bst_recommendations(bst_model, puppy_history, sim.n_products, device, MAX_SEQ_LEN)\n",
    "print(\"Top 5 Recommendations:\")\n",
    "print(puppy_recs.head(5))\n",
    "\n",
    "\n",
    "# --- Test Case 2: Cat Owner Intent ---\n",
    "cat_food_id = sim.products[sim.products['category'] == 'Cat Food'].index[0]\n",
    "cat_toy_id = sim.products[sim.products['category'] == 'Cat Toy'].index[0]\n",
    "cat_history = [cat_food_id, cat_toy_id]\n",
    "\n",
    "print(\"\\n--- Test Case 2: 'Cat' Intent ---\")\n",
    "print(f\"Input History: [Cat Food (ID: {cat_food_id}), Cat Toy (ID: {cat_toy_id})]\")\n",
    "cat_recs = get_bst_recommendations(bst_model, cat_history, sim.n_products, device, MAX_SEQ_LEN)\n",
    "print(\"Top 5 Recommendations:\")\n",
    "print(cat_recs.head(5))\n",
    "\n",
    "\n",
    "# --- Visualizing the difference ---\n",
    "puppy_recs['source'] = 'After Dog Session'\n",
    "cat_recs['source'] = 'After Cat Session'\n",
    "plot_df = pd.concat([puppy_recs, cat_recs])\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=plot_df, x='predicted_ctr', y='category', hue='source',\n",
    "            order=['Dog Toy', 'Dog Food', 'Cat Toy', 'Cat Food', 'Fish Supplies'])\n",
    "plt.title('BST Model Predictions Based on Session History', fontsize=16)\n",
    "plt.xlabel('Predicted CTR')\n",
    "plt.ylabel('Product Category')\n",
    "plt.legend(title='Session Context')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e49189",
   "metadata": {},
   "source": [
    "#### **3.5 Discussion: When Sequence Matters Most**\n",
    "\n",
    "The evaluation plot clearly demonstrates the power of the BST model. After a \"Dog Session,\" the predicted CTRs for `Dog Toy` and `Dog Food` are dramatically higher than for other categories. Conversely, after a \"Cat Session,\" the model correctly shifts its preferences to `Cat Toy` and `Cat Food`. It has successfully learned the short-term sequential patterns in user behavior. This is a capability that our previous models fundamentally lacked.\n",
    "\n",
    "**Strengths of the Sequential Approach:**\n",
    "*   **Captures Intent:** It models the user's current \"mission,\" leading to more relevant and timely recommendations.\n",
    "*   **Dynamic:** The recommendations change instantly as the user interacts with more items in the session.\n",
    "*   **Solves Session Cold-Start:** It can provide meaningful recommendations even for anonymous users or users with no long-term history, as long as they have clicked on at least one item in the current session.\n",
    "\n",
    "**Limitations and Considerations:**\n",
    "*   **Data Requirements:** Sequential models require logs of *ordered* interactions. They perform best when sessions are well-defined and reasonably long.\n",
    "*   **Computational Cost:** Transformers, while highly parallelizable, are more computationally intensive to train and serve than simpler models like the batched MLP or LinUCB.\n",
    "*   **Ignoring Long-Term Preferences:** The pure BST model focuses heavily on the current session. A user's long-term profile (e.g., they are a `budget_shopper` who happens to be buying cat food today) is not explicitly modeled. Advanced architectures often combine sequential models with user embeddings (like those from Chapter 1) to get the best of both worlds.\n",
    "\n",
    "In this chapter, we have added a crucial dimension to our understanding of personalization: the importance of sequence. By modeling the user's journey, we can move from generic predictions to understanding their immediate intent.\n",
    "\n",
    "However, we are still missing one key source of information. So far, all our models have learned about users in isolation. But in a real-world e-commerce platform, users and items form a vast, interconnected network. The behavior of similar users can tell us a lot about what an individual might like. How can we tap into this \"wisdom of the crowd\"? This leads us to our next chapter, where we will explore the world of **Graph-Based Personalization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61322d32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5acad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b9fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26beb980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df79e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13db04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
